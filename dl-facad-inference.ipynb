{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9711412,"sourceType":"datasetVersion","datasetId":5940282}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-24T13:04:00.202245Z","iopub.execute_input":"2024-10-24T13:04:00.202535Z","iopub.status.idle":"2024-10-24T13:04:01.086390Z","shell.execute_reply.started":"2024-10-24T13:04:00.202503Z","shell.execute_reply":"2024-10-24T13:04:01.085453Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/facad-test-dataset/test_dataset.parquet\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install bert-score python-Levenshtein evaluate rouge_score --upgrade nltk","metadata":{"execution":{"iopub.status.busy":"2024-10-24T13:04:01.087880Z","iopub.execute_input":"2024-10-24T13:04:01.088302Z","iopub.status.idle":"2024-10-24T13:04:20.866439Z","shell.execute_reply.started":"2024-10-24T13:04:01.088269Z","shell.execute_reply":"2024-10-24T13:04:20.865515Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting bert-score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nCollecting python-Levenshtein\n  Downloading python_Levenshtein-0.26.0-py3-none-any.whl.metadata (3.7 kB)\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nCollecting nltk\n  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.4.0)\nRequirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.2.2)\nRequirement already satisfied: transformers>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from bert-score) (4.45.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bert-score) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.32.3)\nRequirement already satisfied: tqdm>=4.31.1 in /opt/conda/lib/python3.10/site-packages (from bert-score) (4.66.4)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert-score) (3.7.5)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from bert-score) (21.3)\nCollecting Levenshtein==0.26.0 (from python-Levenshtein)\n  Downloading levenshtein-0.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\nCollecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.26.0->python-Levenshtein)\n  Downloading rapidfuzz-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2024.5.15)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->bert-score) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (2024.8.30)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.1.4)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.20.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (10.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_Levenshtein-0.26.0-py3-none-any.whl (9.4 kB)\nDownloading levenshtein-0.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading rapidfuzz-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=0209f10675bb1f7bdf70f2bdd09cbfa12b5cacf55064f4faf43063cfb4c286dd\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rapidfuzz, nltk, rouge_score, Levenshtein, python-Levenshtein, evaluate, bert-score\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed Levenshtein-0.26.0 bert-score-0.3.13 evaluate-0.4.3 nltk-3.9.1 python-Levenshtein-0.26.0 rapidfuzz-3.10.0 rouge_score-0.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import BlipProcessor, BlipForConditionalGeneration\nfrom transformers import AutoProcessor, AutoModelForCausalLM\nfrom bert_score import score as bertscore\nfrom datasets import load_dataset\nfrom tqdm import tqdm\nimport evaluate \nimport Levenshtein\n\n# Load test dataset using the datasets library\ndata_path = '/kaggle/input/facad-test-dataset/test_dataset.parquet'\ntest_dataset = load_dataset('parquet', data_files=data_path)['train']\ntest_images = test_dataset['image']\ntest_captions = test_dataset['text']","metadata":{"execution":{"iopub.status.busy":"2024-10-24T13:04:20.867956Z","iopub.execute_input":"2024-10-24T13:04:20.868377Z","iopub.status.idle":"2024-10-24T13:04:40.057604Z","shell.execute_reply.started":"2024-10-24T13:04:20.868328Z","shell.execute_reply":"2024-10-24T13:04:40.056781Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74e52ec357514728a7fcb449fefb73d8"}},"metadata":{}}]},{"cell_type":"code","source":"# Load evaluation metrics using the evaluate library\nbleu = evaluate.load('bleu')\nrouge = evaluate.load('rouge')\nmeteor = evaluate.load('meteor')","metadata":{"execution":{"iopub.status.busy":"2024-10-24T13:04:40.060277Z","iopub.execute_input":"2024-10-24T13:04:40.061115Z","iopub.status.idle":"2024-10-24T13:04:43.257251Z","shell.execute_reply.started":"2024-10-24T13:04:40.061066Z","shell.execute_reply":"2024-10-24T13:04:43.256177Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbdc182f52b349eb8ce74f7f5ed3b509"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a7faea8da5c4d07837a6d45b3762e6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfde1df0a222443dbdc55f7ea500b8f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8df0403deb1a476f8e642555cf99575c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.02k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8399f0c139e9404382067486afedd65d"}},"metadata":{}},{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize lists to store generated captions\nblip_captions, blip_finetuned_captions, git_finetuned_captions = [], [], []\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Helper function to generate captions using a given model and processor\ndef generate_captions(model, processor, test_images):\n    captions = []\n    model = model.to(device)\n    model.eval()  \n    with torch.no_grad():\n        for image in tqdm(test_images):\n            inputs = processor(images=image, return_tensors=\"pt\").to(device)\n            pixel_values = inputs.pixel_values\n            generated_ids = model.generate(pixel_values=pixel_values, max_length=50)\n            caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n            captions.append(caption)\n    return captions","metadata":{"execution":{"iopub.status.busy":"2024-10-24T13:04:43.258898Z","iopub.execute_input":"2024-10-24T13:04:43.259251Z","iopub.status.idle":"2024-10-24T13:04:43.315588Z","shell.execute_reply.started":"2024-10-24T13:04:43.259215Z","shell.execute_reply":"2024-10-24T13:04:43.314188Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Load models and processors\nblip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\nblip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n\nblip_finetuned_model = BlipForConditionalGeneration.from_pretrained(\"sagniksengupta/blip-finetuned-facad\")\nblip_finetuned_processor = BlipProcessor.from_pretrained(\"sagniksengupta/blip-finetuned-facad\")\n\ngit_finetuned_model = AutoModelForCausalLM.from_pretrained(\"sagniksengupta/git-finetuned-facad\")\ngit_finetuned_processor = AutoProcessor.from_pretrained(\"sagniksengupta/git-finetuned-facad\")","metadata":{"execution":{"iopub.status.busy":"2024-10-24T13:04:43.317442Z","iopub.execute_input":"2024-10-24T13:04:43.318206Z","iopub.status.idle":"2024-10-24T13:05:35.510606Z","shell.execute_reply.started":"2024-10-24T13:04:43.318150Z","shell.execute_reply":"2024-10-24T13:05:35.509798Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fed29a1505ce47af986a8e1c60e53ebf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9dd4ccacd034213a028d0b714bab3fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"525d3b54c0684c04968a72654b186042"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/506 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"871bc2b0813c40a2b58cb4b722c67749"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2008d34706f54d5a81fc068872c2556a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec37e7a90e304004969d1e5ff94ad2e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bd6f279af3f49f1854955e372f5e439"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/672 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37fc892b0aec4a56a13b46176911555f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5c06568620e4c75b91e15caf9ee45cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/136 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdf920ae7da04479ab17f36acc26cca6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/431 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c36211e95cb64091bbe825e3187e7f32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.45k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c2937e793b4416a977b41d05286d56c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cf98e53811c4261a52cc65158f9adad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"836bc76e82f74dea83467908b907ca93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e4007ab1960431bbdf81dd2c1d67121"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/869 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa3b78c7281444e0be1090bf7e894080"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/707M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70a2deaa91c8433594037baa88aab6c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/136 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"178694c0f62e4ed89739acb9867dc6ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/503 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdb46993cb004e5b8aa919cc9a20845e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19acb072535149e7996ded43e1b2ae11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5535f6f2a4c40998674e4ae3bdeb321"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a673f42ddd7346fb9c62871c0c078109"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e6917f142fe4fa498d8778af5f431a0"}},"metadata":{}}]},{"cell_type":"code","source":"# Generate captions from all three models\nblip_captions = generate_captions(blip_model, blip_processor, test_images)\nblip_finetuned_captions = generate_captions(blip_finetuned_model, blip_finetuned_processor, test_images)\ngit_finetuned_captions = generate_captions(git_finetuned_model, git_finetuned_processor, test_images)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T13:05:35.511700Z","iopub.execute_input":"2024-10-24T13:05:35.512006Z","iopub.status.idle":"2024-10-24T13:27:24.937298Z","shell.execute_reply.started":"2024-10-24T13:05:35.511974Z","shell.execute_reply":"2024-10-24T13:27:24.936342Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"100%|██████████| 1000/1000 [03:37<00:00,  4.59it/s]\n100%|██████████| 1000/1000 [07:46<00:00,  2.14it/s]\n100%|██████████| 1000/1000 [10:23<00:00,  1.60it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate_generated_captions(generated_captions, test_captions):\n    predictions = generated_captions\n    references = [[ref] for ref in test_captions]  \n\n    bleu_scores = bleu.compute(predictions=predictions, references=references)['bleu']\n    \n    rouge_scores = rouge.compute(predictions=generated_captions, references=test_captions)\n    \n    P, R, F1 = bertscore(generated_captions, test_captions, lang='en')\n    bertscore_f1 = F1.mean().item()\n    \n    # Levenshtein distance calculation\n    levenshtein_distances = []\n    for gen_caption, ref_caption in zip(generated_captions, test_captions):\n        distance = Levenshtein.distance(gen_caption, ref_caption)\n        levenshtein_distances.append(distance)\n    \n    avg_levenshtein = sum(levenshtein_distances) / len(levenshtein_distances)\n\n    return {\n        'bleu': bleu_scores,\n        'rouge': rouge_scores['rougeL'],\n        'bertscore_f1': bertscore_f1,\n        'avg_levenshtein': avg_levenshtein\n    }\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T13:35:00.894663Z","iopub.execute_input":"2024-10-24T13:35:00.895619Z","iopub.status.idle":"2024-10-24T13:35:00.903628Z","shell.execute_reply.started":"2024-10-24T13:35:00.895572Z","shell.execute_reply":"2024-10-24T13:35:00.902544Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Evaluate for each model's captions\nblip_metrics = evaluate_generated_captions(blip_captions, test_captions)\nblip_finetuned_metrics = evaluate_generated_captions(blip_finetuned_captions, test_captions)\ngit_finetuned_metrics = evaluate_generated_captions(git_finetuned_captions, test_captions)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T13:35:03.065839Z","iopub.execute_input":"2024-10-24T13:35:03.066269Z","iopub.status.idle":"2024-10-24T13:35:34.745507Z","shell.execute_reply.started":"2024-10-24T13:35:03.066230Z","shell.execute_reply":"2024-10-24T13:35:34.744625Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"BLIP Base Metrics: \", blip_metrics)\nprint(\"BLIP Fine-tuned Metrics: \", blip_finetuned_metrics)\nprint(\"GIT Fine-tuned Metrics: \", git_finetuned_metrics)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T13:35:47.245412Z","iopub.execute_input":"2024-10-24T13:35:47.245876Z","iopub.status.idle":"2024-10-24T13:35:47.251501Z","shell.execute_reply.started":"2024-10-24T13:35:47.245820Z","shell.execute_reply":"2024-10-24T13:35:47.250473Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"BLIP Base Metrics:  {'bleu': 0.0, 'rouge': 0.1295297393210773, 'bertscore_f1': 0.8311129212379456, 'avg_levenshtein': 97.622}\nBLIP Fine-tuned Metrics:  {'bleu': 0.02984166260245386, 'rouge': 0.19304251481728948, 'bertscore_f1': 0.8568896055221558, 'avg_levenshtein': 93.806}\nGIT Fine-tuned Metrics:  {'bleu': 0.009336050760516194, 'rouge': 0.1502710551309211, 'bertscore_f1': 0.8445741534233093, 'avg_levenshtein': 92.806}\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\ndata = [\n    {'Model': 'BLIP Base', 'BLEU': blip_metrics['bleu'], 'ROUGE': blip_metrics['rouge'], 'BERTScore F1': blip_metrics['bertscore_f1'], 'Avg. Levenshtein': blip_metrics['avg_levenshtein']},\n    {'Model': 'BLIP Fine-tuned', 'BLEU': blip_finetuned_metrics['bleu'], 'ROUGE': blip_finetuned_metrics['rouge'], 'BERTScore F1': blip_finetuned_metrics['bertscore_f1'], 'Avg. Levenshtein': blip_finetuned_metrics['avg_levenshtein']},\n    {'Model': 'GIT Fine-tuned', 'BLEU': git_finetuned_metrics['bleu'], 'ROUGE': git_finetuned_metrics['rouge'], 'BERTScore F1': git_finetuned_metrics['bertscore_f1'], 'Avg. Levenshtein': git_finetuned_metrics['avg_levenshtein']}\n]\n\ndf = pd.DataFrame(data)\n\ndf","metadata":{"execution":{"iopub.status.busy":"2024-10-24T13:37:51.721080Z","iopub.execute_input":"2024-10-24T13:37:51.721987Z","iopub.status.idle":"2024-10-24T13:37:51.742218Z","shell.execute_reply.started":"2024-10-24T13:37:51.721944Z","shell.execute_reply":"2024-10-24T13:37:51.741343Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"             Model      BLEU     ROUGE  BERTScore F1  Avg. Levenshtein\n0        BLIP Base  0.000000  0.129530      0.831113            97.622\n1  BLIP Fine-tuned  0.029842  0.193043      0.856890            93.806\n2   GIT Fine-tuned  0.009336  0.150271      0.844574            92.806","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>BLEU</th>\n      <th>ROUGE</th>\n      <th>BERTScore F1</th>\n      <th>Avg. Levenshtein</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BLIP Base</td>\n      <td>0.000000</td>\n      <td>0.129530</td>\n      <td>0.831113</td>\n      <td>97.622</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BLIP Fine-tuned</td>\n      <td>0.029842</td>\n      <td>0.193043</td>\n      <td>0.856890</td>\n      <td>93.806</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GIT Fine-tuned</td>\n      <td>0.009336</td>\n      <td>0.150271</td>\n      <td>0.844574</td>\n      <td>92.806</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}