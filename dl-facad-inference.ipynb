{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9711412,"sourceType":"datasetVersion","datasetId":5940282},{"sourceId":9762256,"sourceType":"datasetVersion","datasetId":5978245}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q bert-score python-Levenshtein evaluate rouge_score ","metadata":{"execution":{"iopub.status.busy":"2024-10-31T03:48:54.129882Z","iopub.execute_input":"2024-10-31T03:48:54.130360Z","iopub.status.idle":"2024-10-31T03:49:16.263014Z","shell.execute_reply.started":"2024-10-31T03:48:54.130306Z","shell.execute_reply":"2024-10-31T03:49:16.261954Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import BlipProcessor, BlipForConditionalGeneration\nfrom transformers import AutoProcessor, AutoModelForCausalLM\nfrom bert_score import score as bertscore\nfrom datasets import load_dataset\nfrom tqdm import tqdm\nimport evaluate \nimport Levenshtein\n\n# Load test dataset using the datasets library\ndata_path = '/kaggle/input/luna-facad-custom/test_dataset-LUNA-FACAD.parquet'\ntest_dataset = load_dataset('parquet', data_files=data_path)['train']\ntest_images = test_dataset['image']\ntest_captions = test_dataset['text']","metadata":{"execution":{"iopub.status.busy":"2024-10-31T03:49:36.930741Z","iopub.execute_input":"2024-10-31T03:49:36.931107Z","iopub.status.idle":"2024-10-31T03:50:08.877452Z","shell.execute_reply.started":"2024-10-31T03:49:36.931071Z","shell.execute_reply":"2024-10-31T03:50:08.876637Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10f752bb934c40e9b75127fa2fbc4842"}},"metadata":{}}]},{"cell_type":"code","source":"# Load evaluation metrics using the evaluate library\nbleu = evaluate.load('bleu')\nrouge = evaluate.load('rouge')\nmeteor = evaluate.load('meteor')","metadata":{"execution":{"iopub.status.busy":"2024-10-31T03:50:37.369134Z","iopub.execute_input":"2024-10-31T03:50:37.370221Z","iopub.status.idle":"2024-10-31T03:50:40.919018Z","shell.execute_reply.started":"2024-10-31T03:50:37.370178Z","shell.execute_reply":"2024-10-31T03:50:40.918200Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e07b8338256478898409af64f1cc888"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eaa64cb754f94bebb287c39da81f3912"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1a4194126414f7cb2818ea307bbc928"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0959fc4f61e6412e8b6a3d119542acbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.02k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9db92834f02244cf86e9646b0b912daa"}},"metadata":{}},{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize lists to store generated captions\nblip_captions, blip_finetuned_captions, git_captions, git_finetuned_captions = [], [], [], []\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Helper function to generate captions using a given model and processor\ndef generate_captions(model, processor, test_images):\n    captions = []\n    model = model.to(device)\n    model.eval()  \n    with torch.no_grad():\n        for image in tqdm(test_images):\n            inputs = processor(images=image, return_tensors=\"pt\").to(device)\n            pixel_values = inputs.pixel_values\n            generated_ids = model.generate(pixel_values=pixel_values, max_length=64)\n            caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n            captions.append(caption)\n    return captions","metadata":{"execution":{"iopub.status.busy":"2024-10-31T03:50:46.908511Z","iopub.execute_input":"2024-10-31T03:50:46.909484Z","iopub.status.idle":"2024-10-31T03:50:46.979532Z","shell.execute_reply.started":"2024-10-31T03:50:46.909432Z","shell.execute_reply":"2024-10-31T03:50:46.978528Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Load models and processors\nblip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\nblip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n\nblip_finetuned_model = BlipForConditionalGeneration.from_pretrained(\"sagniksengupta/blip-finetuned-facad-v2\")\nblip_finetuned_processor = BlipProcessor.from_pretrained(\"sagniksengupta/blip-finetuned-facad-v2\")\n\ngit_model = AutoModelForCausalLM.from_pretrained(\"microsoft/git-base\")\ngit_processor = AutoProcessor.from_pretrained(\"microsoft/git-base\")\n\ngit_finetuned_model = AutoModelForCausalLM.from_pretrained(\"sagniksengupta/git-finetuned-facad-v2\")\ngit_finetuned_processor = AutoProcessor.from_pretrained(\"sagniksengupta/git-finetuned-facad-v2\")","metadata":{"execution":{"iopub.status.busy":"2024-10-31T03:50:49.583730Z","iopub.execute_input":"2024-10-31T03:50:49.584722Z","iopub.status.idle":"2024-10-31T03:51:52.900116Z","shell.execute_reply.started":"2024-10-31T03:50:49.584668Z","shell.execute_reply":"2024-10-31T03:51:52.899347Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5da5ee44853f405495634beffa4018d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25f614ae4a984ee78e7b0b35adcb2e68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bb4080ab9e6432c82818912d11cdcbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/506 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cb7b01d4b2c4ddfbb1b0ea20c1bddd9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae067d77bee844b28e57248ae1f83cf2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83c978eae5d74c7699b0e0faee1c0842"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40bc312d36fe489d8451b59a1a61edcf"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/672 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"050dbc7118b54d728545ca690f73663e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ddb932615be4f4a86de8b79e2654136"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/136 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a8ef42a2ff043628fe3876d2d09b39c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/431 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f63339764fa48a1882954cb8a782181"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.45k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd5b4a4326244e718a1a171b1565b4ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"214dedb9af4d41f39c231d202fb1f86f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c1fed125eaf48ddb0cef500f15b3753"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6dd43be60a74996a2caf6fa444739b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.82k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcd6b6c3c58f467597769cd3fd54fd24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/707M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f85c8784c34448e1bb85b49b6cd0531a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/141 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fee7eab7f4b43bfaa6aaa5d33cd28ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/503 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f959ba20b4724c1dab8e56403985d61c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/453 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c4aa22f88534c34a2e7717b0eedc428"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16f8bfe9cf5041428e3978f4471d5d33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c4c0508dca3451d8cc0ec069d3ad6bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87c0b2b1197d42cab7951853457cdb29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/869 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6467b4c4ac9b48b69da13b160063010d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/707M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf85fa3fb2ea4fa4a055c9b1b35b19ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/136 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cf514c6101b4d5c8dcf403276d22202"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/503 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd56e9b4f278468a82bcf7ee9ef30ccb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa971d01bdbe4245b5c170240e9a5cbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6054b927becb40a79041a5c11ad69df3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0359192e7c3c4584991fc8daa07bd949"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c5bbc00607f4294b0aae4b09fc83fb4"}},"metadata":{}}]},{"cell_type":"code","source":"# Generate captions from all three models\nblip_captions = generate_captions(blip_model, blip_processor, test_images)\nblip_finetuned_captions = generate_captions(blip_finetuned_model, blip_finetuned_processor, test_images)\ngit_captions = generate_captions(git_model, git_processor, test_images)\ngit_finetuned_captions = generate_captions(git_finetuned_model, git_finetuned_processor, test_images)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T03:52:18.268173Z","iopub.execute_input":"2024-10-31T03:52:18.268583Z","iopub.status.idle":"2024-10-31T04:41:07.876158Z","shell.execute_reply.started":"2024-10-31T03:52:18.268544Z","shell.execute_reply":"2024-10-31T04:41:07.875199Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"100%|██████████| 2000/2000 [07:16<00:00,  4.58it/s]\n100%|██████████| 2000/2000 [15:06<00:00,  2.21it/s]\n100%|██████████| 2000/2000 [08:42<00:00,  3.83it/s]\n100%|██████████| 2000/2000 [17:42<00:00,  1.88it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.DataFrame({\n    'image_id': [i for i in range(len(test_images))],\n    'blip_caption': blip_captions,\n    'blip_finetuned_caption': blip_finetuned_captions,\n    'git_caption': git_captions,\n    'git_finetuned_caption': git_finetuned_captions,\n    'original_caption' : test_captions\n})\n\ndf.to_csv('models_captions.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T05:11:13.263899Z","iopub.execute_input":"2024-10-31T05:11:13.264628Z","iopub.status.idle":"2024-10-31T05:11:13.311327Z","shell.execute_reply.started":"2024-10-31T05:11:13.264586Z","shell.execute_reply":"2024-10-31T05:11:13.310413Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-31T05:11:15.410368Z","iopub.execute_input":"2024-10-31T05:11:15.410823Z","iopub.status.idle":"2024-10-31T05:11:15.423936Z","shell.execute_reply.started":"2024-10-31T05:11:15.410784Z","shell.execute_reply":"2024-10-31T05:11:15.422921Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"   image_id                                      blip_caption  \\\n0         0                a woman in a bikini top and bottom   \n1         1       a woman wearing a black top and black pants   \n2         2  a woman wearing a white t - shirt and blue jeans   \n3         3   a woman wearing a yellow jacket and white pants   \n4         4            a woman wearing a black and gold dress   \n\n                              blip_finetuned_caption  \\\n0  a tropical tropical print cover these soft str...   \n1  a soft and stretchy knit enhances the easygoin...   \n2  a faded wash and faded stripe add vintage char...   \n3  a vibrant floral print is the signature of thi...   \n4  a halter neck neckline and a waist defining be...   \n\n                                         git_caption  \\\n0  tropical palm tree bikini bottom in pink and g...   \n1                   black dress with a long neckline   \n2                  person - i ' m in love with this!   \n3            silk silk kimono with a floral pattern.   \n4  black and white dress with a black bow in the ...   \n\n                               git_finetuned_caption  \\\n0  a bold plaid in a modern cut add to the laid b...   \n1  a sleek and sophisticated silhouette defines a...   \n2  a bold plaid in a modern cut add to the modern...   \n3  a bold plaid in a modern cut add to the laid b...   \n4  a sleek and sophisticated silhouette defines a...   \n\n                                    original_caption  \n0  a ruched fold over waistband lends a retrro vi...  \n1  long side slit allow flowy motion in this eleg...  \n2  vintage inspired pinstripe extend the throwbac...  \n3  veronica etro s global travel inform the kalei...  \n4  lightweight crepe fabric give soft yet crisp s...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>blip_caption</th>\n      <th>blip_finetuned_caption</th>\n      <th>git_caption</th>\n      <th>git_finetuned_caption</th>\n      <th>original_caption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>a woman in a bikini top and bottom</td>\n      <td>a tropical tropical print cover these soft str...</td>\n      <td>tropical palm tree bikini bottom in pink and g...</td>\n      <td>a bold plaid in a modern cut add to the laid b...</td>\n      <td>a ruched fold over waistband lends a retrro vi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>a woman wearing a black top and black pants</td>\n      <td>a soft and stretchy knit enhances the easygoin...</td>\n      <td>black dress with a long neckline</td>\n      <td>a sleek and sophisticated silhouette defines a...</td>\n      <td>long side slit allow flowy motion in this eleg...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>a woman wearing a white t - shirt and blue jeans</td>\n      <td>a faded wash and faded stripe add vintage char...</td>\n      <td>person - i ' m in love with this!</td>\n      <td>a bold plaid in a modern cut add to the modern...</td>\n      <td>vintage inspired pinstripe extend the throwbac...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>a woman wearing a yellow jacket and white pants</td>\n      <td>a vibrant floral print is the signature of thi...</td>\n      <td>silk silk kimono with a floral pattern.</td>\n      <td>a bold plaid in a modern cut add to the laid b...</td>\n      <td>veronica etro s global travel inform the kalei...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>a woman wearing a black and gold dress</td>\n      <td>a halter neck neckline and a waist defining be...</td>\n      <td>black and white dress with a black bow in the ...</td>\n      <td>a sleek and sophisticated silhouette defines a...</td>\n      <td>lightweight crepe fabric give soft yet crisp s...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install git+https://github.com/salaniz/pycocoevalcap","metadata":{"execution":{"iopub.status.busy":"2024-10-31T04:45:01.952785Z","iopub.execute_input":"2024-10-31T04:45:01.953228Z","iopub.status.idle":"2024-10-31T04:45:27.502099Z","shell.execute_reply.started":"2024-10-31T04:45:01.953187Z","shell.execute_reply":"2024-10-31T04:45:27.500888Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting git+https://github.com/salaniz/pycocoevalcap\n  Cloning https://github.com/salaniz/pycocoevalcap to /tmp/pip-req-build-t4_psuda\n  Running command git clone --filter=blob:none --quiet https://github.com/salaniz/pycocoevalcap /tmp/pip-req-build-t4_psuda\n  Resolved https://github.com/salaniz/pycocoevalcap to commit a24f74c408c918f1f4ec34e9514bc8a76ce41ffd\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting pycocotools>=2.0.2 (from pycocoevalcap==1.2)\n  Downloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools>=2.0.2->pycocoevalcap==1.2) (3.7.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pycocotools>=2.0.2->pycocoevalcap==1.2) (1.26.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (10.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (1.16.0)\nDownloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.8/427.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pycocoevalcap\n  Building wheel for pycocoevalcap (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pycocoevalcap: filename=pycocoevalcap-1.2-py3-none-any.whl size=104312246 sha256=d53f12beb91bcc81861a52bd2d7fe1f9edb05578f42961f37eec4e5d83b93e96\n  Stored in directory: /tmp/pip-ephem-wheel-cache-kj4uqyme/wheels/43/54/73/3e2c6d4ace7657958cde52ac6fd47b342cd4aae5a7aa4fcbf9\nSuccessfully built pycocoevalcap\nInstalling collected packages: pycocotools, pycocoevalcap\nSuccessfully installed pycocoevalcap-1.2 pycocotools-2.0.8\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\nimport Levenshtein\nfrom bert_score import score as bertscore\nfrom pycocoevalcap.cider.cider import Cider\n\n# Load BLEU, ROUGE, METEOR metrics\nbleu = evaluate.load(\"bleu\")\nrouge = evaluate.load(\"rouge\")\nmeteor = evaluate.load(\"meteor\")\ncider_scorer = Cider()\n\ndef evaluate_generated_captions(generated_captions, test_captions):\n    predictions = generated_captions\n    references = [[ref] for ref in test_captions]  \n\n    # Compute BLEU score\n    bleu_scores = bleu.compute(predictions=predictions, references=references)['bleu']\n    \n    # Compute ROUGE score\n    rouge_scores = rouge.compute(predictions=generated_captions, references=test_captions)\n    \n    # Compute BERTScore\n    P, R, F1 = bertscore(generated_captions, test_captions, lang='en')\n    bertscore_f1 = F1.mean().item()\n    \n    # Compute METEOR\n    meteor_score = meteor.compute(predictions=generated_captions, references=test_captions)['meteor']\n    \n    # Compute CIDEr using pycocoevalcap\n    cider_score, _ = cider_scorer.compute_score({i: [test_captions[i]] for i in range(len(test_captions))},\n                                                {i: [generated_captions[i]] for i in range(len(generated_captions))})\n    \n    # Levenshtein distance calculation\n    levenshtein_distances = []\n    for gen_caption, ref_caption in zip(generated_captions, test_captions):\n        distance = Levenshtein.distance(gen_caption, ref_caption)\n        levenshtein_distances.append(distance)\n    \n    avg_levenshtein = sum(levenshtein_distances) / len(levenshtein_distances)\n\n    return {\n        'bleu': bleu_scores,\n        'rouge': rouge_scores['rougeL'],\n        'bertscore_f1': bertscore_f1,\n        'meteor': meteor_score,\n        'cider': cider_score,\n        'avg_levenshtein': avg_levenshtein\n    }\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T04:45:37.631649Z","iopub.execute_input":"2024-10-31T04:45:37.632065Z","iopub.status.idle":"2024-10-31T04:45:38.913361Z","shell.execute_reply.started":"2024-10-31T04:45:37.632022Z","shell.execute_reply":"2024-10-31T04:45:38.912457Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate for each model's captions\nblip_metrics = evaluate_generated_captions(blip_captions, test_captions)\nblip_finetuned_metrics = evaluate_generated_captions(blip_finetuned_captions, test_captions)\ngit_metrics = evaluate_generated_captions(git_captions, test_captions)\ngit_finetuned_metrics = evaluate_generated_captions(git_finetuned_captions, test_captions)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T04:46:02.139162Z","iopub.execute_input":"2024-10-31T04:46:02.139942Z","iopub.status.idle":"2024-10-31T04:47:48.042811Z","shell.execute_reply.started":"2024-10-31T04:46:02.139898Z","shell.execute_reply":"2024-10-31T04:47:48.041972Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47549cbc4b914b579aff0c779605f303"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6bd934a9b9741959784eec784cd3de6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab9c25e5d13a446a9310df3fa09adcbc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4292a8435801411dbe92b29dbf36ca40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc4c65dfa2144b61bfb068530ad4a285"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78c770d56812445dbd6d79df9f130831"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"BLIP Base Metrics: \", blip_metrics)\nprint(\"BLIP Fine-tuned Metrics: \", blip_finetuned_metrics)\nprint(\"GIT Base Metrics: \", git_metrics)\nprint(\"GIT Fine-tuned Metrics: \", git_finetuned_metrics)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T04:48:13.455903Z","iopub.execute_input":"2024-10-31T04:48:13.456811Z","iopub.status.idle":"2024-10-31T04:48:13.462243Z","shell.execute_reply.started":"2024-10-31T04:48:13.456766Z","shell.execute_reply":"2024-10-31T04:48:13.461309Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"BLIP Base Metrics:  {'bleu': 0.0, 'rouge': 0.12953131437101992, 'bertscore_f1': 0.8314244151115417, 'meteor': 0.07409039076770353, 'cider': 0.0283613746907342, 'avg_levenshtein': 99.032}\nBLIP Fine-tuned Metrics:  {'bleu': 0.029762342665750632, 'rouge': 0.19355394248821906, 'bertscore_f1': 0.8587872385978699, 'meteor': 0.17190936897690273, 'cider': 0.3147401795912754, 'avg_levenshtein': 94.496}\nGIT Base Metrics:  {'bleu': 0.0, 'rouge': 0.10306075301954873, 'bertscore_f1': 0.831838846206665, 'meteor': 0.059931826324370795, 'cider': 0.02208585987285886, 'avg_levenshtein': 100.74}\nGIT Fine-tuned Metrics:  {'bleu': 0.003863721661089574, 'rouge': 0.13013510797965544, 'bertscore_f1': 0.8465403914451599, 'meteor': 0.08927323377048495, 'cider': 0.05665661261245232, 'avg_levenshtein': 91.657}\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\ndata = [\n    {'Model': 'BLIP Base', 'BLEU': blip_metrics['bleu'], 'ROUGE': blip_metrics['rouge'], 'BERTScore F1': blip_metrics['bertscore_f1'], 'Avg. Levenshtein': blip_metrics['avg_levenshtein'], 'METEOR': blip_metrics['meteor'], 'CIDEr': blip_metrics['cider']},\n    {'Model': 'BLIP Fine-tuned', 'BLEU': blip_finetuned_metrics['bleu'], 'ROUGE': blip_finetuned_metrics['rouge'], 'BERTScore F1': blip_finetuned_metrics['bertscore_f1'], 'Avg. Levenshtein': blip_finetuned_metrics['avg_levenshtein'], 'METEOR': blip_finetuned_metrics['meteor'], 'CIDEr': blip_finetuned_metrics['cider']},\n    {'Model': 'GIT Base', 'BLEU': git_metrics['bleu'], 'ROUGE': git_metrics['rouge'], 'BERTScore F1': git_metrics['bertscore_f1'], 'Avg. Levenshtein': git_metrics['avg_levenshtein'], 'METEOR': git_metrics['meteor'], 'CIDEr': git_metrics['cider']},\n    {'Model': 'GIT Fine-tuned', 'BLEU': git_finetuned_metrics['bleu'], 'ROUGE': git_finetuned_metrics['rouge'], 'BERTScore F1': git_finetuned_metrics['bertscore_f1'], 'Avg. Levenshtein': git_finetuned_metrics['avg_levenshtein'], 'METEOR': git_finetuned_metrics['meteor'], 'CIDEr': git_finetuned_metrics['cider']}\n]\n\ndf = pd.DataFrame(data)\n\ndf\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T04:49:20.818283Z","iopub.execute_input":"2024-10-31T04:49:20.819082Z","iopub.status.idle":"2024-10-31T04:49:20.843585Z","shell.execute_reply.started":"2024-10-31T04:49:20.819020Z","shell.execute_reply":"2024-10-31T04:49:20.842475Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"             Model      BLEU     ROUGE  BERTScore F1  Avg. Levenshtein  \\\n0        BLIP Base  0.000000  0.129531      0.831424            99.032   \n1  BLIP Fine-tuned  0.029762  0.193554      0.858787            94.496   \n2         GIT Base  0.000000  0.103061      0.831839           100.740   \n3   GIT Fine-tuned  0.003864  0.130135      0.846540            91.657   \n\n     METEOR     CIDEr  \n0  0.074090  0.028361  \n1  0.171909  0.314740  \n2  0.059932  0.022086  \n3  0.089273  0.056657  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>BLEU</th>\n      <th>ROUGE</th>\n      <th>BERTScore F1</th>\n      <th>Avg. Levenshtein</th>\n      <th>METEOR</th>\n      <th>CIDEr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BLIP Base</td>\n      <td>0.000000</td>\n      <td>0.129531</td>\n      <td>0.831424</td>\n      <td>99.032</td>\n      <td>0.074090</td>\n      <td>0.028361</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BLIP Fine-tuned</td>\n      <td>0.029762</td>\n      <td>0.193554</td>\n      <td>0.858787</td>\n      <td>94.496</td>\n      <td>0.171909</td>\n      <td>0.314740</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GIT Base</td>\n      <td>0.000000</td>\n      <td>0.103061</td>\n      <td>0.831839</td>\n      <td>100.740</td>\n      <td>0.059932</td>\n      <td>0.022086</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GIT Fine-tuned</td>\n      <td>0.003864</td>\n      <td>0.130135</td>\n      <td>0.846540</td>\n      <td>91.657</td>\n      <td>0.089273</td>\n      <td>0.056657</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom transformers import BlipProcessor, BlipForConditionalGeneration, VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer, CLIPProcessor, CLIPModel\n\n# Load the CLIP model and processor, then move the model to the GPU if available\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nclip_model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\").to(device)\nclip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n\n# Define a function to compute CLIP logits for an image and list of captions\ndef get_clip_logits(image, captions):\n    # Prepare inputs and move them to the appropriate device\n    inputs = clip_processor(text=captions, images=image, return_tensors=\"pt\", padding=True).to(device)\n    outputs = clip_model(**inputs)\n    logits_per_image = outputs.logits_per_image  # Image-text similarity scores\n    return logits_per_image\n\n# Define a function to compute CLIP logits for a batch of images and captions\ndef calculate_clip_logits_for_captions(image_list, caption_list):\n    logits = []\n    for image, caption in zip(image_list, caption_list):\n        logits_per_image = get_clip_logits(image, [caption])\n        logits.append(logits_per_image.item())  # Extract the scalar value for each image-caption pair\n    return logits\n\n# Generate CLIP logits for each model's captions\nblip_clip_logits = calculate_clip_logits_for_captions(test_images, blip_captions)\nblip_finetuned_clip_logits = calculate_clip_logits_for_captions(test_images, blip_finetuned_captions)\ngit_clip_logits = calculate_clip_logits_for_captions(test_images, git_captions)\ngit_finetuned_clip_logits = calculate_clip_logits_for_captions(test_images, git_finetuned_captions)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T05:00:02.813265Z","iopub.execute_input":"2024-10-31T05:00:02.813655Z","iopub.status.idle":"2024-10-31T05:09:29.155012Z","shell.execute_reply.started":"2024-10-31T05:00:02.813611Z","shell.execute_reply":"2024-10-31T05:09:29.154163Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"data = [\n    {'Model': 'BLIP Base', 'BLEU': blip_metrics['bleu'], 'ROUGE': blip_metrics['rouge'], 'BERTScore F1': blip_metrics['bertscore_f1'], 'Avg. Levenshtein': blip_metrics['avg_levenshtein'], 'METEOR': blip_metrics['meteor'], 'CIDEr': blip_metrics['cider'], 'Avg. CLIP Logits': torch.mean(torch.tensor(blip_clip_logits)).item()},\n    {'Model': 'BLIP Fine-tuned', 'BLEU': blip_finetuned_metrics['bleu'], 'ROUGE': blip_finetuned_metrics['rouge'], 'BERTScore F1': blip_finetuned_metrics['bertscore_f1'], 'Avg. Levenshtein': blip_finetuned_metrics['avg_levenshtein'], 'METEOR': blip_finetuned_metrics['meteor'], 'CIDEr': blip_finetuned_metrics['cider'], 'Avg. CLIP Logits': torch.mean(torch.tensor(blip_finetuned_clip_logits)).item()},\n    {'Model': 'GIT Base', 'BLEU': git_metrics['bleu'], 'ROUGE': git_metrics['rouge'], 'BERTScore F1': git_metrics['bertscore_f1'], 'Avg. Levenshtein': git_metrics['avg_levenshtein'], 'METEOR': git_metrics['meteor'], 'CIDEr': git_metrics['cider'], 'Avg. CLIP Logits': torch.mean(torch.tensor(git_clip_logits)).item()},\n    {'Model': 'GIT Fine-tuned', 'BLEU': git_finetuned_metrics['bleu'], 'ROUGE': git_finetuned_metrics['rouge'], 'BERTScore F1': git_finetuned_metrics['bertscore_f1'], 'Avg. Levenshtein': git_finetuned_metrics['avg_levenshtein'], 'METEOR': git_finetuned_metrics['meteor'], 'CIDEr': git_finetuned_metrics['cider'], 'Avg. CLIP Logits': torch.mean(torch.tensor(git_finetuned_clip_logits)).item()}\n]\n\ndf = pd.DataFrame(data)\n\ndf","metadata":{"execution":{"iopub.status.busy":"2024-10-31T05:14:01.046520Z","iopub.execute_input":"2024-10-31T05:14:01.047363Z","iopub.status.idle":"2024-10-31T05:14:01.082044Z","shell.execute_reply.started":"2024-10-31T05:14:01.047308Z","shell.execute_reply":"2024-10-31T05:14:01.081078Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"             Model      BLEU     ROUGE  BERTScore F1  Avg. Levenshtein  \\\n0        BLIP Base  0.000000  0.129531      0.831424            99.032   \n1  BLIP Fine-tuned  0.029762  0.193554      0.858787            94.496   \n2         GIT Base  0.000000  0.103061      0.831839           100.740   \n3   GIT Fine-tuned  0.003864  0.130135      0.846540            91.657   \n\n     METEOR     CIDEr  Avg. CLIP Logits  \n0  0.074090  0.028361         23.352610  \n1  0.171909  0.314740         25.839006  \n2  0.059932  0.022086         24.227318  \n3  0.089273  0.056657         13.080656  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>BLEU</th>\n      <th>ROUGE</th>\n      <th>BERTScore F1</th>\n      <th>Avg. Levenshtein</th>\n      <th>METEOR</th>\n      <th>CIDEr</th>\n      <th>Avg. CLIP Logits</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BLIP Base</td>\n      <td>0.000000</td>\n      <td>0.129531</td>\n      <td>0.831424</td>\n      <td>99.032</td>\n      <td>0.074090</td>\n      <td>0.028361</td>\n      <td>23.352610</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BLIP Fine-tuned</td>\n      <td>0.029762</td>\n      <td>0.193554</td>\n      <td>0.858787</td>\n      <td>94.496</td>\n      <td>0.171909</td>\n      <td>0.314740</td>\n      <td>25.839006</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GIT Base</td>\n      <td>0.000000</td>\n      <td>0.103061</td>\n      <td>0.831839</td>\n      <td>100.740</td>\n      <td>0.059932</td>\n      <td>0.022086</td>\n      <td>24.227318</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GIT Fine-tuned</td>\n      <td>0.003864</td>\n      <td>0.130135</td>\n      <td>0.846540</td>\n      <td>91.657</td>\n      <td>0.089273</td>\n      <td>0.056657</td>\n      <td>13.080656</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.to_csv('model_metrics.csv')","metadata":{"execution":{"iopub.status.busy":"2024-10-31T05:14:03.051113Z","iopub.execute_input":"2024-10-31T05:14:03.051995Z","iopub.status.idle":"2024-10-31T05:14:03.057372Z","shell.execute_reply.started":"2024-10-31T05:14:03.051954Z","shell.execute_reply":"2024-10-31T05:14:03.056520Z"},"trusted":true},"execution_count":25,"outputs":[]}]}